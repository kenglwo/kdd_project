{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Hx_ORp9PvBq"
   },
   "source": [
    "# Install/import packages and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "U0lCazmmWEA7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import statistics\n",
    "import time\n",
    "from itertools import combinations\n",
    "import sktime\n",
    "from sktime import datasets\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from numba import njit\n",
    "from numba import prange\n",
    "from numba import vectorize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lWVKaGyyQCZB"
   },
   "source": [
    "# Definitions of the train and transform functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "7x52_4H1akJU"
   },
   "outputs": [],
   "source": [
    "# return diltation choices for each kernel (an array of at most size 32), number of features in each dilation, bias trained from the example\n",
    "\n",
    "@njit(\n",
    "    fastmath=True,\n",
    "    parallel=True,\n",
    "    cache=False,\n",
    ")\n",
    "def train(X):\n",
    "  # hyperparameter and metadata from dataset\n",
    "  num_training_data, input_len = X.shape\n",
    "  num_kernel = 84 # 9C3\n",
    "  num_feature = 10000\n",
    "  max_dilation_size = 32\n",
    "  # print(\"num_training_data = {}, input_len = {}\".format(num_training_data, input_len))\n",
    "\n",
    "  # calculate the dilation choices for each kernel and their number of features\n",
    "  num_feature_per_kernel = num_feature // num_kernel\n",
    "  max_dilation = min(max_dilation_size, num_feature_per_kernel)\n",
    "  max_exponent = np.log2((input_len - 1) / (9 - 1))\n",
    "  uniform_exponent = [ 1 + i*((max_exponent-1)/(max_dilation-1)) for i in range(max_dilation)]\n",
    "  dilation_choices = [math.floor(2**x) for x in uniform_exponent]\n",
    "  num_feature_in_dilation = [num_feature_per_kernel // max_dilation for _ in range(len(dilation_choices))]\n",
    "  for i in range(num_feature_per_kernel-(num_feature_per_kernel//max_dilation)*max_dilation): # add one to first k elem so that sum(num_feature_in_dilation)==num_feature_per_kernel\n",
    "    num_feature_in_dilation[i] += 1\n",
    "  #print(\"dilation_choices = {}, \\nnum_feature_in_dilation = {}, \\nnum_feature_per_kernel = {}\".format(dilation_choices, num_feature_in_dilation, num_feature_per_kernel))\n",
    "\n",
    "  # calculate the low-discrepancy_sequence sequence for bias\n",
    "  # from wiki, r_i = (a*r_(i-1) + c) mod m where a, m = 1 and c can be sqrt(2)-1\n",
    "  low_discrepancy_sequence = [(i*(math.sqrt(2)-1))%1 for i in range(1, num_feature+1)]\n",
    "\n",
    "  # calculate bias\n",
    "  num_feature = num_feature_per_kernel * num_kernel # change the input num_feature to real num_feature\n",
    "  # beta_indices = np.array([_ for _ in combinations(np.arange(9), 3)]) # shape of (84, 3), indicating the indices of beta in the kernel\n",
    "  \n",
    "  beta_indices = np.array(\n",
    "        (\n",
    "            0, 1, 2, 0, 1, 3, 0, 1, 4, 0, \n",
    "            1, 5, 0, 1, 6, 0, 1, 7, 0, 1, \n",
    "            8, 0, 2, 3, 0, 2, 4, 0, 2, 5, \n",
    "            0, 2, 6, 0, 2, 7, 0, 2, 8, 0, \n",
    "            3, 4, 0, 3, 5, 0, 3, 6, 0, 3, \n",
    "            7, 0, 3, 8, 0, 4, 5, 0, 4, 6, \n",
    "            0, 4, 7, 0, 4, 8, 0, 5, 6, 0, \n",
    "            5, 7, 0, 5, 8, 0, 6, 7, 0, 6, \n",
    "            8, 0, 7, 8, 1, 2, 3, 1, 2, 4, \n",
    "            1, 2, 5, 1, 2, 6, 1, 2, 7, 1, \n",
    "            2, 8, 1, 3, 4, 1, 3, 5, 1, 3, \n",
    "            6, 1, 3, 7, 1, 3, 8, 1, 4, 5, \n",
    "            1, 4, 6, 1, 4, 7, 1, 4, 8, 1, \n",
    "            5, 6, 1, 5, 7, 1, 5, 8, 1, 6, \n",
    "            7, 1, 6, 8, 1, 7, 8, 2, 3, 4, \n",
    "            2, 3, 5, 2, 3, 6, 2, 3, 7, 2, \n",
    "            3, 8, 2, 4, 5, 2, 4, 6, 2, 4, \n",
    "            7, 2, 4, 8, 2, 5, 6, 2, 5, 7, \n",
    "            2, 5, 8, 2, 6, 7, 2, 6, 8, 2, \n",
    "            7, 8, 3, 4, 5, 3, 4, 6, 3, 4, \n",
    "            7, 3, 4, 8, 3, 5, 6, 3, 5, 7, \n",
    "            3, 5, 8, 3, 6, 7, 3, 6, 8, 3, \n",
    "            7, 8, 4, 5, 6, 4, 5, 7, 4, 5, \n",
    "            8, 4, 6, 7, 4, 6, 8, 4, 7, 8, \n",
    "            5, 6, 7, 5, 6, 8, 5, 7, 8, 6, \n",
    "            7, 8),\n",
    "\n",
    "        dtype=np.int32,\n",
    "    ).reshape(84, 3)    \n",
    "    \n",
    "  bias = np.zeros(num_feature, dtype = np.float32)\n",
    "  current_feature_index = 0\n",
    "  for i in range(len(dilation_choices)):\n",
    "    for j in range(num_kernel):\n",
    "      dilation = dilation_choices[i]\n",
    "      padding = 4 * dilation\n",
    "      num_feature_in_this_dilation = num_feature_in_dilation[i]\n",
    "    \n",
    "      idx_0, idx_1, idx_2 = beta_indices[j]\n",
    "      C = np.zeros((num_training_data, input_len), dtype = np.float32)\n",
    "        \n",
    "      for idx in range(num_training_data):\n",
    "\n",
    "        _X = X[idx]\n",
    "        alpha_X = -1 * _X\n",
    "        gamma_X = 3 * _X # gamma = 2 - (-1) = 3\n",
    "\n",
    "        C_alpha = np.zeros(input_len, dtype=np.float32) # it's actually the column sum of C_alpha\n",
    "        C_alpha += alpha_X # the 4th row\n",
    "        C_gamma = np.zeros(input_len, dtype=np.float32) # it's actually the column sum of C_gamma for those row in beta_indices[j]\n",
    "        start = padding # for first half\n",
    "        end = input_len - dilation # for lower half\n",
    "    \n",
    "        for row_idx in range(4):\n",
    "          C_alpha[start:] += alpha_X[:input_len-start]\n",
    "          if row_idx in beta_indices[j]:\n",
    "            C_gamma[start:] += gamma_X[:input_len-start]\n",
    "          start -= dilation\n",
    "        if 4 in beta_indices[j]:\n",
    "          C_gamma += gamma_X\n",
    "        for row_idx in range(5, 9):\n",
    "          C_alpha[:end] += alpha_X[input_len-end:]\n",
    "          if row_idx in beta_indices[j]:\n",
    "            C_gamma[:end] += gamma_X[input_len-end:]\n",
    "          end -= dilation\n",
    "        \n",
    "        C[idx] = C_alpha + C_gamma[idx_0] + C_gamma[idx_1] + C_gamma[idx_2]\n",
    "      bias[current_feature_index:current_feature_index+num_feature_in_this_dilation] = \\\n",
    "      np.quantile(C, low_discrepancy_sequence[current_feature_index:current_feature_index+num_feature_in_this_dilation])\n",
    "      current_feature_index += num_feature_in_this_dilation\n",
    "  #print(\"bias.shape = {}\".format(bias.shape))\n",
    "  return dilation_choices, num_feature_in_dilation, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@vectorize(\"float32(float32,float32)\", nopython=True, cache=False)\n",
    "def sign_minus_b_vect(c, b):\n",
    "  return 1 if c-b>=0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "7PEJ4i6SUMf9"
   },
   "outputs": [],
   "source": [
    "@njit(\n",
    "    fastmath=True,\n",
    "    parallel=True,\n",
    "    cache=False,\n",
    ")\n",
    "\n",
    "# transform new input to features given dilation_choices, num_feature_in_dilation and bias\n",
    "def transform(X, dilation_choices, num_feature_in_dilation, bias):\n",
    "  num_transform_data, input_len = X.shape\n",
    "  num_kernel = 84 # 9C3\n",
    "\n",
    "  # beta_indices = np.array([_ for _ in combinations(np.arange(9), 3)]) # shape of (84, 3), indicating the indices of beta in the kernel\n",
    "  beta_indices = np.array(\n",
    "        (\n",
    "            0, 1, 2, 0, 1, 3, 0, 1, 4, 0, \n",
    "            1, 5, 0, 1, 6, 0, 1, 7, 0, 1, \n",
    "            8, 0, 2, 3, 0, 2, 4, 0, 2, 5, \n",
    "            0, 2, 6, 0, 2, 7, 0, 2, 8, 0, \n",
    "            3, 4, 0, 3, 5, 0, 3, 6, 0, 3, \n",
    "            7, 0, 3, 8, 0, 4, 5, 0, 4, 6, \n",
    "            0, 4, 7, 0, 4, 8, 0, 5, 6, 0, \n",
    "            5, 7, 0, 5, 8, 0, 6, 7, 0, 6, \n",
    "            8, 0, 7, 8, 1, 2, 3, 1, 2, 4, \n",
    "            1, 2, 5, 1, 2, 6, 1, 2, 7, 1, \n",
    "            2, 8, 1, 3, 4, 1, 3, 5, 1, 3, \n",
    "            6, 1, 3, 7, 1, 3, 8, 1, 4, 5, \n",
    "            1, 4, 6, 1, 4, 7, 1, 4, 8, 1, \n",
    "            5, 6, 1, 5, 7, 1, 5, 8, 1, 6, \n",
    "            7, 1, 6, 8, 1, 7, 8, 2, 3, 4, \n",
    "            2, 3, 5, 2, 3, 6, 2, 3, 7, 2, \n",
    "            3, 8, 2, 4, 5, 2, 4, 6, 2, 4, \n",
    "            7, 2, 4, 8, 2, 5, 6, 2, 5, 7, \n",
    "            2, 5, 8, 2, 6, 7, 2, 6, 8, 2, \n",
    "            7, 8, 3, 4, 5, 3, 4, 6, 3, 4, \n",
    "            7, 3, 4, 8, 3, 5, 6, 3, 5, 7, \n",
    "            3, 5, 8, 3, 6, 7, 3, 6, 8, 3, \n",
    "            7, 8, 4, 5, 6, 4, 5, 7, 4, 5, \n",
    "            8, 4, 6, 7, 4, 6, 8, 4, 7, 8, \n",
    "            5, 6, 7, 5, 6, 8, 5, 7, 8, 6, \n",
    "            7, 8),\n",
    "\n",
    "        dtype=np.int32,\n",
    "    ).reshape(84, 3) \n",
    "    \n",
    "  features = np.zeros((num_transform_data, num_kernel*sum(num_feature_in_dilation)), dtype = np.float32)\n",
    "  \n",
    "  for data_idx in range(num_transform_data):\n",
    "    #print(\"progress: {}/{}\".format(data_idx+1,num_transform_data))\n",
    "    alpha_X = -1 * X[data_idx]\n",
    "    gamma_X = 3 * X[data_idx]\n",
    "    current_feature_index = 0\n",
    "    for dilation_idx in range(len(dilation_choices)):\n",
    "      dilation = dilation_choices[dilation_idx]\n",
    "      padding = 4 * dilation\n",
    "      num_feature_in_this_dilation = num_feature_in_dilation[dilation_idx]\n",
    "\n",
    "      # compute C_aplha and C_gamma for the data\n",
    "      C_alpha = np.zeros(input_len, dtype=np.float32) # it's actually the column sum of C_alpha\n",
    "      C_alpha += alpha_X # the 4th row\n",
    "      C_gamma = np.zeros((9, input_len), dtype=np.float32) # the real C_gamma (9, input_len)\n",
    "      start = padding # for first half\n",
    "      end = input_len - dilation # for lower half\n",
    "      for row_idx in range(4):\n",
    "        C_alpha[start:] += alpha_X[:input_len-start]\n",
    "        C_gamma[row_idx, start:] += gamma_X[:input_len-start]\n",
    "        start -= dilation\n",
    "      C_gamma[4] = gamma_X\n",
    "      for row_idx in range(5, 9):\n",
    "        C_alpha[:end] += alpha_X[input_len-end:]\n",
    "        C_gamma[row_idx, :end] += gamma_X[input_len-end:]\n",
    "        end -= dilation\n",
    "\n",
    "      # for each kernel, compute feature from C = C_aplha + some rows in C_gamma and the bias\n",
    "      for kernel_idx in range(num_kernel):\n",
    "        beta_0, beta_1, beta_2 = beta_indices[kernel_idx]\n",
    "        C = C_alpha + C_gamma[beta_0] + C_gamma[beta_1] + C_gamma[beta_2]\n",
    "\n",
    "        for i in range(num_feature_in_this_dilation):\n",
    "          b = bias[current_feature_index+i]\n",
    "          sign_of_C_minus_b = sign_minus_b_vect(C, b)\n",
    "          if (data_idx + kernel_idx)%2: # half consider padding and half don't consider when calculating the PPV\n",
    "            sign_of_C_minus_b = sign_of_C_minus_b[padding:-padding]\n",
    "          features[data_idx, current_feature_index+i] = sign_of_C_minus_b.mean()\n",
    "        current_feature_index += num_feature_in_this_dilation\n",
    "  return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ipcJGGvgQ9So"
   },
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xeFx4Au1-S9C",
    "outputId": "14b3e166-93de-4e83-cb50-736df56c3520"
   },
   "outputs": [],
   "source": [
    "X_train, y_train = sktime.datasets.load_UCR_UEA_dataset('ArrowHead', split=\"train\", return_X_y=True)\n",
    "X_test, y_test = sktime.datasets.load_UCR_UEA_dataset('ArrowHead', split=\"test\", return_X_y=True)\n",
    "X_train = np.array([[x for x in n.tolist()[0].tolist()] for n in X_train.to_numpy()])\n",
    "X_test = np.array([[x for x in n.tolist()[0].tolist()] for n in X_test.to_numpy()])\n",
    "print(\"X_train.shape = {}, y_train.shape = {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"X_test.shape = {}, y_test.shape = {}\".format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "js-yibMt9XZl",
    "outputId": "81df1387-bc7b-44fd-f639-a1b49379a377"
   },
   "outputs": [],
   "source": [
    "# # interesting, just swap the two\n",
    "# X_test, y_test = sktime.datasets.load_UCR_UEA_dataset('ArrowHead', split=\"train\", return_X_y=True)\n",
    "# X_train, y_train = sktime.datasets.load_UCR_UEA_dataset('ArrowHead', split=\"test\", return_X_y=True)\n",
    "# X_test = np.array([[x for x in n.tolist()[0].tolist()] for n in X_test.to_numpy()])\n",
    "# X_train = np.array([[x for x in n.tolist()[0].tolist()] for n in X_train.to_numpy()])\n",
    "# print(\"X_train.shape = {}, y_train.shape = {}\".format(X_train.shape, y_train.shape))\n",
    "# print(\"X_test.shape = {}, y_test.shape = {}\".format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lhSpxZRg-dyS",
    "outputId": "5d84df81-35d0-4d0e-cd6e-97ec1c07db55"
   },
   "outputs": [],
   "source": [
    "dilation_choices, num_feature_in_dilation, bias = train(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m9kiYVjdhe7B",
    "outputId": "ee55cb39-15d8-461b-9d96-718c7b825ded"
   },
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "X_train_transform = transform(X_train, dilation_choices, num_feature_in_dilation, bias)\n",
    "t1 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time took for training: 14.85231614112854\n"
     ]
    }
   ],
   "source": [
    "print(\"Time took for training: {}\".format(t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J1CztKC3V4Ln",
    "outputId": "77f4c98b-5f56-49e0-b0e3-9e396131e82e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler(with_mean=False)),\n",
       "                ('ridgeclassifiercv',\n",
       "                 RidgeClassifierCV(alphas=array([1.00000000e-03, 4.64158883e-03, 2.15443469e-02, 1.00000000e-01,\n",
       "       4.64158883e-01, 2.15443469e+00, 1.00000000e+01, 4.64158883e+01,\n",
       "       2.15443469e+02, 1.00000000e+03])))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = make_pipeline(StandardScaler(with_mean=False), RidgeClassifierCV(alphas = np.logspace(-3, 3, 10)))\n",
    "model.fit(X_train_transform, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v5nRfRO9W9iR",
    "outputId": "ddc4bb6f-2f3c-419d-df31-3ca8835b6120"
   },
   "outputs": [],
   "source": [
    "t2 = time.time()\n",
    "X_test_transform = transform(X_test, dilation_choices, num_feature_in_dilation, bias)\n",
    "t3 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time took for testing: 43.45445704460144\n"
     ]
    }
   ],
   "source": [
    "print(\"Time took for testing: {}\".format(t3-t2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lcFrlJtJXqM7",
    "outputId": "22a81c70-cb28-4c07-d52e-46904ea25daf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7771428571428571\n"
     ]
    }
   ],
   "source": [
    "print(model.score(X_test_transform, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0KRJG5fARCJV"
   },
   "source": [
    "# Whiteboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lz9UHSkbVL5x",
    "outputId": "c693617d-1d23-4c80-c5b9-6814daadd06d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1', '2', '0', '1', '2', '0', '1', '2', '0', '1', '2', '0',\n",
       "       '1', '2', '0', '1', '2', '0', '1', '2', '0', '1', '2', '0', '1',\n",
       "       '2', '0', '1', '2', '0', '1', '2', '0', '1', '2'], dtype='<U1')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VxleGgO1VVqh",
    "outputId": "a268f978-b2e4-450e-ea44-30cea1b38edc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(175, 251)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-iczyUeBYLWi",
    "outputId": "476cf54f-3801-437b-fb26-7f5dad234712"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 251)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PvpNATIVZ4hp",
    "outputId": "f2410c6f-5573-40cf-d94c-5d9abab0cae6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '2', '2', '2', '2', '2', '2', '2', '2',\n",
       "       '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2',\n",
       "       '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2',\n",
       "       '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2',\n",
       "       '2', '2', '2', '2', '2', '2'], dtype='<U1')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RKzXhrZxcxjK",
    "outputId": "77c7cd80-f9a2-4938-8b92-266547bddcd8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(175, 9996)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_transform.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KMXUZfsUYnCD",
    "outputId": "b9564df1-efd3-4860-e5c7-99ca03c326eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9444444444444444\n",
      "0.8076117038726807\n"
     ]
    }
   ],
   "source": [
    "from sktime.transformations.panel.rocket import Rocket,MiniRocket, MiniRocketMultivariate\n",
    "import time\n",
    "t0 = time.time()\n",
    "X_train, y_train = sktime.datasets.load_UCR_UEA_dataset('ArrowHead', split=\"test\", return_X_y=True) \n",
    "minirocket = MiniRocket()\n",
    "minirocket.fit(X_train)\n",
    "model2 = make_pipeline(StandardScaler(with_mean=False), RidgeClassifierCV(alphas = np.logspace(-3, 3, 10)))\n",
    "X_train_transform = minirocket.transform(X_train)\n",
    "model2.fit(X_train_transform, y_train)\n",
    "X_test, y_test = sktime.datasets.load_UCR_UEA_dataset('ArrowHead', split=\"train\", return_X_y=True)\n",
    "X_test_transform = minirocket.transform(X_test)\n",
    "print(model2.score(X_test_transform, y_test))\n",
    "print(time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ojJhJtVEny0",
    "outputId": "80f33191-0d61-4fe2-df7a-68def66537c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(175, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F_-BsQtqEzqr",
    "outputId": "e5982e65-74fd-4968-fdb6-78355dced50d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WjzeF_QfE4Vs",
    "outputId": "cdfb940a-2264-4ef6-b005-70ebde843137"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1635598413.9945385"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YmGijMn4PiuD"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "_Hx_ORp9PvBq",
    "lWVKaGyyQCZB",
    "0KRJG5fARCJV"
   ],
   "name": "MyMiniRocket.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
